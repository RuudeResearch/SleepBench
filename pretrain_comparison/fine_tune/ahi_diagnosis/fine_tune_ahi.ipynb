{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd().split('/pretrain_comparison/fine_tune/ahi_diagnosis')[0] + '/pretrain_comparison')\n",
    "from fine_tune.models.model import SleepEventLSTMClassifier\n",
    "from fine_tune.models.dataset import SleepEventClassificationDataset, finetune_collate_fn\n",
    "from fine_tune.utils import *\n",
    "from comparison.utils import *\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.getcwd().split('/pretrain_comparison/fine_tune/ahi_diagnosis')[0] + '/pretrain_comparison/fine_tune/config_fine_tune.yaml'\n",
    "config = load_data(config_path)\n",
    "#config[\"batch_size\"] = config[\"batch_size\"] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class SleepEventClassificationDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 channel_groups=None,\n",
    "                 hdf5_paths=[],\n",
    "                 split=\"train\",\n",
    "                 pretrain_type = \"MAE\",\n",
    "                 specific_files = None):\n",
    "\n",
    "        self.config = config\n",
    "        #self.max_channels = self.config[\"max_channels\"]\n",
    "        self.context = int(self.config[\"context\"])\n",
    "        self.channel_like = self.config[\"channel_like\"]\n",
    "\n",
    "        #diagnosis, death, and demographics\n",
    "        self.df_demographics = pd.read_csv(config['demographics_labels_path'])\n",
    "        self.df_diagnosis_presence = pd.read_csv(os.path.join(config['diagnosis_labels_path'], 'is_event.csv'))\n",
    "        self.df_diagnosis_time = pd.read_csv(os.path.join(config['diagnosis_labels_path'], 'time_to_event.csv'))\n",
    "        self.df_death_presence = pd.read_csv(os.path.join(config['death_labels_path'], 'is_event.csv'), usecols=['Study ID','death'])\n",
    "        self.df_death_time = pd.read_csv(os.path.join(config['death_labels_path'], 'time_to_event.csv'), usecols=['Study ID','death'])\n",
    "        self.df_ahi = pd.read_csv(config['ahi_labels_path'])\n",
    "        self.df_ahi['diagnosis'] = self.df_ahi.ahi.apply(lambda x: 1 if x >= 15 else 0)\n",
    "\n",
    "        unique_study_ids_in_demo_diag_death = set(self.df_demographics['Study ID'].values).intersection(set(self.df_diagnosis_presence['Study ID'].values)).intersection(set(self.df_diagnosis_time['Study ID'].values)).intersection(set(self.df_death_presence['Study ID'].values)).intersection(set(self.df_death_time['Study ID'].values))\n",
    "        unique_study_ids_in_demo_diag_death = set(self.df_ahi['Study ID'].values).intersection(unique_study_ids_in_demo_diag_death)\n",
    "\n",
    "        labels_path = self.config[\"labels_path\"]\n",
    "        dataset = self.config[\"dataset\"]\n",
    "        dataset = dataset.split(\",\")\n",
    "\n",
    "        label_files = []\n",
    "\n",
    "        for dataset_name in dataset:\n",
    "            label_files += glob.glob(os.path.join(labels_path, dataset_name, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "        # label_files = [label_file for label_file in os.listdir(labels_path) if label_file.endswith(\".csv\")]\n",
    "\n",
    "        hdf5_paths = load_data(config[\"split_path\"])[split]\n",
    "        #print(f'first hdf5_paths: {hdf5_paths[0]}')\n",
    "        #print(f'len hdf5_paths: {len(hdf5_paths)}')\n",
    "        #print(f'first label_files: {label_files[0]}')\n",
    "        #print(f'len label_files: {len(label_files)}')\n",
    "        study_ids = set([os.path.basename(label_file).split(\".\")[0] for label_file in label_files])\n",
    "        #print(f'first study_ids: {list(study_ids)[0]}')\n",
    "        #print(f'len study_ids: {len(study_ids)}')\n",
    "\n",
    "        hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        #print(f'len hdf5_paths: {len(hdf5_paths)}')\n",
    "        hdf5_paths = [f for f in hdf5_paths if f.split(\"/\")[-1].split(\".\")[0] in study_ids]\n",
    "        hdf5_paths = [f for f in hdf5_paths if f.split(\"/\")[-1].split(\".\")[0] in unique_study_ids_in_demo_diag_death]\n",
    "        #print(f'len hdf5_paths: {len(hdf5_paths)}')\n",
    "\n",
    "        hdf5_paths_ids = set([os.path.basename(hdf5_path).split(\".\")[0] for hdf5_path in hdf5_paths])\n",
    "        #print(f'first hdf5_paths_ids: {list(hdf5_paths_ids)[0]}')\n",
    "        #print(f'len hdf5_paths_ids: {len(hdf5_paths_ids)}')\n",
    "\n",
    "        hdf5_paths_new = []\n",
    "        #print(f'dataset: {dataset}')\n",
    "        #for dataset_name in dataset:\n",
    "            #hdf5_paths_new += glob.glob(os.path.join(config[\"embedding_path\"], dataset_name, \"**\", \"*.hdf5\"), recursive=True)\n",
    "        hdf5_paths_new += glob.glob(os.path.join(config[\"embedding_path\"], pretrain_type, \"**\", \"*.hdf5\"), recursive=True)\n",
    "        #print(f'first hdf5_paths_new: {hdf5_paths_new[0]}')\n",
    "        \n",
    "        #print(f'len hdf5_paths_new: {len(hdf5_paths_new)}')\n",
    "        \n",
    "        hdf5_paths_new = [item for item in hdf5_paths_new if os.path.basename(item).split(\".\")[0] in hdf5_paths_ids]\n",
    "        #print(f'len hdf5_paths_new: {len(hdf5_paths_new)}')\n",
    "        hdf5_paths = hdf5_paths_new\n",
    "        hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        #print(f'len hdf5_paths: {len(hdf5_paths)}')\n",
    "\n",
    "        if config[\"max_files\"]:\n",
    "            hdf5_paths = hdf5_paths[:config[\"max_files\"]]\n",
    "        else:\n",
    "            hdf5_paths = hdf5_paths\n",
    "\n",
    "        labels_dict = {\n",
    "            os.path.basename(item).split(\".\")[0]: item for item in label_files\n",
    "        }\n",
    "        if specific_files:\n",
    "            #print(f'hdf5_paths[0] {hdf5_paths[0]}')\n",
    "            #print(f'specific_files[0] {specific_files[0]}')\n",
    "            \n",
    "            # Extract base names from specific_files (without extension) for proper comparison\n",
    "            specific_files_base = [os.path.splitext(f)[0] for f in specific_files]\n",
    "            \n",
    "            # Filter hdf5_paths to only include files whose base names are in specific_files\n",
    "            hdf5_paths = [f for f in hdf5_paths if os.path.splitext(os.path.basename(f))[0] in specific_files_base]\n",
    "            \n",
    "            #print(f'number of specific_files: {len(hdf5_paths)}')\n",
    "            repeats = max(1024 // len(specific_files), 1)\n",
    "            \n",
    "            # Repeat the hdf5 files\n",
    "            hdf5_paths = [f for f in hdf5_paths for _ in range(repeats)]\n",
    "            #print(f'number of training items per epoch: {len(hdf5_paths)}')\n",
    "        if self.context == -1:\n",
    "            self.index_map = [(path, labels_dict[path.split(\"/\")[-1].split(\".\")[0]], -1) for path in hdf5_paths]\n",
    "        else:\n",
    "            self.index_map = []\n",
    "            loop = tqdm(hdf5_paths[:], total=len(hdf5_paths), desc=f\"Indexing {split} data\")\n",
    "            for hdf5_file_path in loop:\n",
    "                file_prefix = os.path.basename(hdf5_file_path).split(\".\")[0]\n",
    "                with h5py.File(hdf5_file_path, \"r\") as file:\n",
    "                    dataset_names = list(file.keys())[:]\n",
    "                    dataset_name = dataset_names[0]\n",
    "                    dataset_length = file[dataset_name].shape[0]\n",
    "                    for i in range(0, dataset_length, self.context):\n",
    "                        self.index_map.append((hdf5_file_path, labels_dict[file_prefix], i))           \n",
    "            \n",
    "        #logger.info(f\"Number of files in {split} set: {len(hdf5_paths)}\")\n",
    "        #logger.info(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "        self.total_len = len(self.index_map)\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def get_index_map(self):\n",
    "        return self.index_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, label_path, start_index = self.index_map[idx]\n",
    "        labels_df = pd.read_csv(label_path)\n",
    "        y_data = labels_df[\"StageNumber\"].to_numpy()\n",
    "        if self.context != -1:\n",
    "            y_data = y_data[start_index:start_index+self.context]\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, 'r') as hf:\n",
    "            dset_names = list(hf.keys())[:]\n",
    "            for dataset_name in dset_names:\n",
    "                x_data.append(hf[dataset_name][:])\n",
    "        x_data = np.array(x_data)\n",
    "        # Convert x_data to tensor\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "        min_length = min(x_data.shape[1], len(y_data))\n",
    "        x_data = x_data[:, :min_length, :].squeeze()\n",
    "        y_data = y_data[:min_length]\n",
    "        \n",
    "        #diagnosis, death, and demographics\n",
    "        study_id = os.path.basename(hdf5_path).split(\".\")[0]\n",
    "        try:\n",
    "            diagnosis_presence = torch.tensor(self.df_diagnosis_presence[self.df_diagnosis_presence['Study ID'] == study_id].values[0][1:].astype(np.float32))\n",
    "            diagnosis_time = torch.tensor(self.df_diagnosis_time[self.df_diagnosis_time['Study ID'] == study_id].values[0][1:].astype(np.float32))\n",
    "            death_presence = torch.tensor(self.df_death_presence[self.df_death_presence['Study ID'] == study_id].values[0][1:].astype(np.float32))\n",
    "            death_time = torch.tensor(self.df_death_time[self.df_death_time['Study ID'] == study_id].values[0][1:].astype(np.float32))\n",
    "            age = torch.tensor(self.df_demographics[self.df_demographics['Study ID'] == study_id]['Age at Study Date'].values) / 100\n",
    "            ahi_diagnosis = torch.tensor(self.df_ahi[self.df_ahi['Study ID'] == study_id]['diagnosis'].values)\n",
    "        except:\n",
    "            print(f'Study ID {study_id} not found in demographics, diagnosis, or death data')\n",
    "\n",
    "        \n",
    "        return x_data, y_data, self.max_seq_len, hdf5_path, diagnosis_presence, diagnosis_time, death_presence, death_time, age, ahi_diagnosis\n",
    "\n",
    "def finetune_collate_fn(batch):\n",
    "\n",
    "    x_data, y_data, max_seq_len_list, hdf5_path_list, diagnosis_presence, diagnosis_time, death_presence, death_time, age, ahi_diagnosis = zip(*batch)\n",
    "\n",
    "    # padding the temporal as in sleep_event_finetune_full_collate_fn\n",
    "    max_seq_len_temp = max([item.size(0) for item in x_data])\n",
    "    # Determine the max sequence length for padding\n",
    "    if max_seq_len_list[0] is None:\n",
    "        max_seq_len = max_seq_len_temp\n",
    "    else:\n",
    "        max_seq_len = min(max_seq_len_temp, max_seq_len_list[0])\n",
    "    \n",
    "    padded_x_data = []\n",
    "    padded_y_data = []\n",
    "    padded_mask = []\n",
    "    diagnosis_presence_list = []\n",
    "    diagnosis_time_list = []\n",
    "    death_presence_list = []\n",
    "    death_time_list = []\n",
    "    age_list = []\n",
    "    ahi_diagnosis_list = []\n",
    "\n",
    "    for x_item, y_item, diagnosis_presence_item, diagnosis_time_item, death_presence_item, death_time_item, age_item, ahi_diagnosis_item  in zip(x_data, y_data, diagnosis_presence, diagnosis_time, death_presence, death_time, age, ahi_diagnosis):\n",
    "        # Get the shape of x_item\n",
    "        s, e = x_item.size()\n",
    "\n",
    "        s = min(s, max_seq_len)\n",
    "\n",
    "        # Create a padded tensor and a mask tensor for x_data\n",
    "        padded_x_item = torch.zeros((max_seq_len, e))\n",
    "        mask = torch.ones((max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        padded_x_item[:s, :e] = x_item[:s, :e]\n",
    "        mask[:s] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        # Pad y_data with zeros to match max_seq_len\n",
    "        padded_y_item = torch.zeros(max_seq_len)\n",
    "        padded_y_item[:s] = y_item[:s]\n",
    "\n",
    "        # Append padded items to lists\n",
    "        padded_x_data.append(padded_x_item)\n",
    "        padded_y_data.append(padded_y_item)\n",
    "        padded_mask.append(mask)\n",
    "        diagnosis_presence_list.append(diagnosis_presence_item)\n",
    "        diagnosis_time_list.append(diagnosis_time_item)\n",
    "        death_presence_list.append(death_presence_item)\n",
    "        death_time_list.append(death_time_item)\n",
    "        age_list.append(age_item)\n",
    "        ahi_diagnosis_list.append(ahi_diagnosis_item)\n",
    "\n",
    "\n",
    "\n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    y_data = torch.stack(padded_y_data)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "\n",
    "    diagnosis_presence = torch.stack(diagnosis_presence_list)\n",
    "    diagnosis_time = torch.stack(diagnosis_time_list)\n",
    "    death_presence = torch.tensor(death_presence_list).unsqueeze(1)\n",
    "    death_time = torch.tensor(death_time_list).unsqueeze(1)\n",
    "    age = torch.tensor(age_list).unsqueeze(1)\n",
    "    ahi_diagnosis = torch.tensor(ahi_diagnosis_list).unsqueeze(1)\n",
    "    \n",
    "    return x_data, y_data, padded_mask, hdf5_path_list, diagnosis_presence, diagnosis_time, death_presence, death_time, age, ahi_diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/oak/stanford/groups/jamesz/magnusrk/pretraining_comparison')\n",
    "from comparison.utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "#model classes\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_seq_len, d_model):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_seq_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads=1, dropout=0.1):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, \n",
    "            nhead=num_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        batch_size, seq_len, input_dim = x.size()\n",
    "        \n",
    "        if key_padding_mask is not None:\n",
    "            if key_padding_mask.size(1) == 1:\n",
    "                return x.mean(dim=1)\n",
    "            if key_padding_mask.dtype != torch.bool:\n",
    "                key_padding_mask = key_padding_mask.to(dtype=torch.bool)\n",
    "                \n",
    "        transformer_output = self.transformer_layer(x, src_key_padding_mask=key_padding_mask)\n",
    "        pooled_output = transformer_output.mean(dim=1)  # Average pooling over the sequence length\n",
    "        \n",
    "        return pooled_output\n",
    "\n",
    "class SleepEventLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_layers, num_classes, pooling_head=4, dropout=0.1, max_seq_length=128):\n",
    "        super(SleepEventLSTMClassifier, self).__init__()\n",
    "        \n",
    "        # Define spatial pooling\n",
    "        #self.spatial_pooling = AttentionPooling(embed_dim, num_heads=pooling_head, dropout=dropout)\n",
    "\n",
    "        # Set max sequence length\n",
    "        if max_seq_length is None:\n",
    "            max_seq_length = 20000\n",
    "            \n",
    "        self.positional_encoding = PositionalEncoding(max_seq_length, embed_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Transformer encoder for spatial modeling\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True, norm_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # LSTM for temporal modeling\n",
    "        lstm_dropout = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=embed_dim//2, num_layers=num_layers, batch_first=True, dropout=lstm_dropout, bidirectional=True)\n",
    "        \n",
    "        # Fully connected layer for sleep stage classification\n",
    "        self.fc_sleep_stage = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "        self.temporal_pooling = AttentionPooling(embed_dim, num_heads=pooling_head, dropout=dropout)\n",
    "\n",
    "        self.fc_age = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 1),\n",
    "            nn.Softplus()  # Ensures smooth, non-negative outputs\n",
    "        )\n",
    "\n",
    "        self.fc_ahi_diagnosis = nn.Linear(embed_dim, 1)\n",
    "\n",
    "        self.fc_death = nn.Linear(embed_dim, 1)\n",
    "\n",
    "        self.fc_diagnosis = nn.Linear(embed_dim, 12)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        B, S, E = x.shape       \n",
    "        device = x.device \n",
    "\n",
    "        # Apply positional encoding and layer normalization\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        # Apply transformer encoder for spatial modeling\n",
    "        mask_temporal = mask[:, :]\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=mask_temporal)\n",
    "\n",
    "        # Apply LSTM for temporal modeling\n",
    "        x, _ = self.lstm(x)  # Shape: (B, S, E)\n",
    "\n",
    "        # Apply the final fully connected layer for classification\n",
    "        sleep_stage = self.fc_sleep_stage(x)  # Shape: (B, S, num_classes)\n",
    "\n",
    "        \n",
    "        #x_diagnosis = self.temporal_pooling_diagnosis(x, mask_temporal)\n",
    "        #x_death = self.temporal_pooling_death(x, mask_temporal)\n",
    "        #x_age = self.temporal_pooling_age(x, mask_temporal)\n",
    "        x = self.temporal_pooling(x, mask_temporal)\n",
    "        hazards_death = self.fc_death(x)\n",
    "        hazards_diagnosis = self.fc_diagnosis(x)\n",
    "        age = self.fc_age(x)\n",
    "        ahi_diagnosis = self.fc_ahi_diagnosis(x)\n",
    "\n",
    "        return sleep_stage.to(device), mask[:, :].to(device), age.to(device), hazards_diagnosis.to(device), hazards_death.to(device), ahi_diagnosis.to(device)  # Return mask along temporal dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(model, data, optimizer=None, scaler=None, config=None, device=None, mode='train'):\n",
    "    \"\"\"\n",
    "    Run one iteration (batch) of training or validation.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model\n",
    "        data: Tuple of batch data\n",
    "        optimizer: PyTorch optimizer (only needed for training)\n",
    "        scaler: Gradient scaler for mixed precision training\n",
    "        config: Configuration dictionary\n",
    "        device: PyTorch device\n",
    "        mode: Either 'train' or 'val'\n",
    "    \"\"\"\n",
    "    is_training = mode == 'train'\n",
    "    \n",
    "    # Unpack the batch data\n",
    "    x_data, y_data, mask, _, diagnosis_presence, diagnosis_time, death_presence, death_time, age_target, ahi_diagnosis_target = data\n",
    "    \n",
    "    # Move data to device\n",
    "    x_data = x_data.to(device)\n",
    "    y_data = y_data.to(device)\n",
    "    mask = mask.bool().to(device)\n",
    "    diagnosis_presence = diagnosis_presence.to(device)\n",
    "    diagnosis_time = diagnosis_time.to(device)\n",
    "    death_presence = death_presence.to(device)\n",
    "    death_time = death_time.to(device)\n",
    "    age_target = age_target.to(device)\n",
    "    ahi_diagnosis_target = ahi_diagnosis_target.to(device)\n",
    "\n",
    "    if is_training:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Context manager for mixed precision training\n",
    "    with torch.cuda.amp.autocast() if is_training else torch.no_grad():\n",
    "        output, mask, age_out, hazards_diagnosis, hazards_death, ahi_diagnosis = model(x_data, mask)\n",
    "        \n",
    "        # Reshape outputs and targets\n",
    "        output_reshaped = output.reshape(-1, config['model_params']['num_classes'])\n",
    "        targets_reshaped = y_data.reshape(-1).long()\n",
    "        \n",
    "        # Handle masking\n",
    "        if mask is not None:\n",
    "            mask_reshaped = mask.reshape(-1)\n",
    "            valid_targets = targets_reshaped != -1\n",
    "            valid_mask = ~mask_reshaped & valid_targets\n",
    "            # Force contiguous memory layout before indexing\n",
    "\n",
    "            # If using DataParallel, ensure tensors are on the same device\n",
    "            if isinstance(model, torch.nn.DataParallel):\n",
    "                device = torch.device(f'cuda:{model.device_ids[0]}')\n",
    "                output_reshaped = output_reshaped.to(device)\n",
    "                valid_mask = valid_mask.to(device)\n",
    "\n",
    "            valid_mask = valid_mask.contiguous()\n",
    "            output_reshaped = output_reshaped.contiguous()\n",
    "            targets_reshaped = targets_reshaped.contiguous()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # if no valid targets set losses to 0 and return\n",
    "            if targets_reshaped.size(0) == 0:\n",
    "                loss = torch.tensor(0.0).to(device)\n",
    "                metrics = {\n",
    "                    'loss': loss.item(),\n",
    "                    'loss_sleep_staging': loss.item(),\n",
    "                    'loss_diagnosis': loss.item(),\n",
    "                    'loss_death': loss.item(),\n",
    "                    'loss_age': loss.item(),\n",
    "                    'loss_ahi_diagnosis': loss.item(),\n",
    "                    'correct': 0,\n",
    "                    'total': 0,\n",
    "                    'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "                    'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "                    'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "                }\n",
    "                return metrics\n",
    "        \n",
    "        # Calculate losses\n",
    "        if mode == 'train':\n",
    "            loss_sleep_staging = torch.tensor(0.0, device=device, requires_grad=True)#masked_cross_entropy_loss(output, y_data, None)\n",
    "            loss_diagnosis = cox_ph_loss(hazards_diagnosis, diagnosis_time, diagnosis_presence)\n",
    "            loss_death = cox_ph_loss(hazards_death, death_time, death_presence)\n",
    "            loss_age = F.mse_loss(age_target.float(), age_out.float())\n",
    "            loss_ahi_diagnosis = F.binary_cross_entropy_with_logits(ahi_diagnosis, ahi_diagnosis_target.float())\n",
    "            loss = loss_ahi_diagnosis\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                loss_sleep_staging = torch.tensor(0.0, device=device)#masked_cross_entropy_loss(output, y_data, mask)\n",
    "                loss_diagnosis = cox_ph_loss(hazards_diagnosis, diagnosis_time, diagnosis_presence)\n",
    "                loss_death = cox_ph_loss(hazards_death, death_time, death_presence)\n",
    "                loss_age = F.mse_loss(age_target.float(), age_out.float())\n",
    "                loss_ahi_diagnosis = F.binary_cross_entropy_with_logits(ahi_diagnosis, ahi_diagnosis_target.float())\n",
    "                loss = loss_ahi_diagnosis\n",
    "\n",
    "    # Handle backpropagation for training\n",
    "    if is_training:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    # Calculate metrics\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(output_reshaped, 1)\n",
    "        total = targets_reshaped.size(0)\n",
    "        correct = (predicted == targets_reshaped).sum().item()\n",
    "        \n",
    "        # Calculate F1 components\n",
    "        tp = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        fp = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        fn = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        \n",
    "        for class_idx in range(config['model_params']['num_classes']):\n",
    "            pred_mask = predicted == class_idx\n",
    "            target_mask = targets_reshaped == class_idx\n",
    "            \n",
    "            tp[class_idx] += (pred_mask & target_mask).sum()\n",
    "            fp[class_idx] += (pred_mask & ~target_mask).sum()\n",
    "            fn[class_idx] += (~pred_mask & target_mask).sum()\n",
    "    # Before returning, check for NaN values\n",
    "    metrics = {\n",
    "        'loss': loss.item(),\n",
    "        'loss_sleep_staging': loss_sleep_staging.item(),\n",
    "        'loss_diagnosis': loss_diagnosis.item(),\n",
    "        'loss_death': loss_death.item(),\n",
    "        'loss_age': loss_age.item(),\n",
    "        'loss_ahi_diagnosis': loss_ahi_diagnosis.item(),\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    }\n",
    "\n",
    "    # Check for NaN values\n",
    "    \n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, (float, int)):\n",
    "            if math.isnan(value):\n",
    "                print(f\"NaN detected in {key}\")\n",
    "                print(f\"Debug info:\")\n",
    "                print(f\"loss: {loss}\")\n",
    "                print(f\"loss_sleep_staging: {loss_sleep_staging}\")\n",
    "                print(f\"loss_diagnosis: {loss_diagnosis}\")\n",
    "                print(f\"loss_death: {loss_death}\")\n",
    "                print(f\"loss_age: {loss_age}\")\n",
    "                print(f\"y_data: {y_data}\")\n",
    "                print(f\"output: {output}\")\n",
    "                print(f\"valid_mask: {valid_mask}\")\n",
    "                print(f\"nan in y data: {torch.isnan(y_data).any()}\")\n",
    "                print(f\"nan in output: {torch.isnan(output).any()}\")\n",
    "                print(f\"nan in valid_mask: {torch.isnan(valid_mask).any()}\")\n",
    "                unique_targets_reshaped = torch.unique(targets_reshaped)\n",
    "                print(f\"unique targets: {unique_targets_reshaped}\")\n",
    "                unique_valid_mask = torch.unique(valid_mask)\n",
    "                print(f\"unique valid mask: {unique_valid_mask}\")\n",
    "                raise ValueError(f\"NaN detected in {key}\")\n",
    "                \n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, optimizer, scaler, config, device, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training metrics\n",
    "        train_metrics = {\n",
    "            'running_loss': 0.0,\n",
    "            'running_sleep_staging_loss': 0.0,\n",
    "            'running_diagnosis_loss': 0.0,\n",
    "            'running_death_loss': 0.0,\n",
    "            'running_age_loss': 0.0,\n",
    "            'running_ahi_diagnosis_loss': 0.0,\n",
    "            'correct': 0,\n",
    "            'total': 0,\n",
    "            'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        }\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        train_loop = tqdm(enumerate(train_loader), \n",
    "                            total=len(train_loader), \n",
    "                            desc=f'Epoch {epoch}/{config[\"epochs\"]-1}',\n",
    "                            leave=True,\n",
    "                            ncols=250)\n",
    "        \n",
    "        for i, batch_data in train_loop:\n",
    "            batch_metrics = run_iteration(model, batch_data, optimizer, scaler, config, device, mode='train')\n",
    "            \n",
    "            # Update running metrics\n",
    "            train_metrics['running_loss'] += batch_metrics['loss']\n",
    "            train_metrics['running_sleep_staging_loss'] += batch_metrics['loss_sleep_staging']\n",
    "            train_metrics['running_diagnosis_loss'] += batch_metrics['loss_diagnosis']\n",
    "            train_metrics['running_death_loss'] += batch_metrics['loss_death']\n",
    "            train_metrics['running_age_loss'] += batch_metrics['loss_age']\n",
    "            train_metrics['running_ahi_diagnosis_loss'] += batch_metrics['loss_ahi_diagnosis']\n",
    "            train_metrics['correct'] += batch_metrics['correct']\n",
    "            train_metrics['total'] += batch_metrics['total']\n",
    "            train_metrics['tp'] += batch_metrics['tp']\n",
    "            train_metrics['fp'] += batch_metrics['fp']\n",
    "            train_metrics['fn'] += batch_metrics['fn']\n",
    "\n",
    "            # Calculate current metrics for progress bar\n",
    "            batch_count = i + 1\n",
    "            avg_loss = train_metrics['running_loss'] / batch_count\n",
    "            accuracy = train_metrics['correct'] / train_metrics['total'] if train_metrics['total'] > 0 else 0\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            precision = train_metrics['tp'] / (train_metrics['tp'] + train_metrics['fp'] + 1e-7)\n",
    "            recall = train_metrics['tp'] / (train_metrics['tp'] + train_metrics['fn'] + 1e-7)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "            macro_f1 = f1.mean().item()\n",
    "\n",
    "            train_loop.set_postfix({\n",
    "                'loss': f'cur:{batch_metrics[\"loss\"]:.3f}/avg:{avg_loss:.3f}',\n",
    "                'sleep': f'cur:{batch_metrics[\"loss_sleep_staging\"]:.3f}/acc:{accuracy:.3f}/f1:{macro_f1:.3f}',\n",
    "                'diag': f'cur:{batch_metrics[\"loss_diagnosis\"]:.3f}',\n",
    "                'death': f'cur:{batch_metrics[\"loss_death\"]:.3f}',\n",
    "                'age': f'cur:{batch_metrics[\"loss_age\"]:.3f}',\n",
    "                'ahi': f'cur:{batch_metrics[\"loss_ahi_diagnosis\"]:.3f}/avg:{train_metrics[\"running_ahi_diagnosis_loss\"] / batch_count:.3f}'\n",
    "            })\n",
    "\n",
    "        # Validation loop\n",
    "        val_metrics = {\n",
    "            'running_loss': 0.0,\n",
    "            'running_sleep_staging_loss': 0.0,\n",
    "            'running_diagnosis_loss': 0.0,\n",
    "            'running_death_loss': 0.0,\n",
    "            'running_age_loss': 0.0,\n",
    "            'running_ahi_diagnosis_loss': 0.0,\n",
    "            'correct': 0,\n",
    "            'total': 0,\n",
    "            'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        }\n",
    "\n",
    "        model.eval()\n",
    "        val_loop = tqdm(enumerate(validation_loader), \n",
    "                        total=len(validation_loader), \n",
    "                        desc=f'Validation Epoch {epoch}/{config[\"epochs\"]-1}',\n",
    "                        leave=True,\n",
    "                        ncols=250)\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in val_loop:\n",
    "                batch_metrics = run_iteration(model, batch_data, None, None, config, device, mode='val')\n",
    "                    \n",
    "                \n",
    "                # Update validation metrics\n",
    "                val_metrics['running_loss'] += batch_metrics['loss']\n",
    "                val_metrics['running_sleep_staging_loss'] += batch_metrics['loss_sleep_staging']\n",
    "                val_metrics['running_diagnosis_loss'] += batch_metrics['loss_diagnosis']\n",
    "                val_metrics['running_death_loss'] += batch_metrics['loss_death']\n",
    "                val_metrics['running_age_loss'] += batch_metrics['loss_age']\n",
    "                val_metrics['running_ahi_diagnosis_loss'] += batch_metrics['loss_ahi_diagnosis']\n",
    "                val_metrics['correct'] += batch_metrics['correct']\n",
    "                val_metrics['total'] += batch_metrics['total']\n",
    "                val_metrics['tp'] += batch_metrics['tp']\n",
    "                val_metrics['fp'] += batch_metrics['fp']\n",
    "                val_metrics['fn'] += batch_metrics['fn']\n",
    "\n",
    "                # Calculate current metrics\n",
    "                batch_count = i + 1\n",
    "                avg_val_loss = val_metrics['running_loss'] / batch_count\n",
    "                val_accuracy = val_metrics['correct'] / val_metrics['total'] if val_metrics['total'] > 0 else 0\n",
    "                \n",
    "                # Calculate F1 score\n",
    "                precision = val_metrics['tp'] / (val_metrics['tp'] + val_metrics['fp'] + 1e-7)\n",
    "                recall = val_metrics['tp'] / (val_metrics['tp'] + val_metrics['fn'] + 1e-7)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "                val_macro_f1 = f1.mean().item()\n",
    "\n",
    "                val_loop.set_postfix({\n",
    "                    'val_loss': f'cur:{batch_metrics[\"loss\"]:.3f}/avg:{avg_val_loss:.3f}',\n",
    "                    'sleep': f'cur:{batch_metrics[\"loss_sleep_staging\"]:.3f}/acc:{val_accuracy:.3f}/f1:{val_macro_f1:.3f}',\n",
    "                    'diag': f'cur:{batch_metrics[\"loss_diagnosis\"]:.3f}',\n",
    "                    'death': f'cur:{batch_metrics[\"loss_death\"]:.3f}',\n",
    "                    'age': f'cur:{batch_metrics[\"loss_age\"]:.3f}',\n",
    "                    'ahi': f'cur:{batch_metrics[\"loss_ahi_diagnosis\"]:.3f}/avg:{val_metrics[\"running_ahi_diagnosis_loss\"] / batch_count:.3f}'\n",
    "                })\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping trigger\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "        print(f'\\nEpoch {epoch} Summary: Training Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, F1: {macro_f1:.4f} Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_macro_f1:.4f} Best validation loss: {best_val_loss:.4f} Patience counter: {patience_counter}/{patience}')\n",
    "\n",
    "    print('\\nTraining finished!')\n",
    "    print(f'Best validation loss: {best_val_loss:.4f}') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scaler, config, model_path):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'config': config\n",
    "    }, model_path)\n",
    "    print(f'Model saved at {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, test_loader, output_path, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and save predictions and targets.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test set\n",
    "        output_path: Path to save results\n",
    "        device: PyTorch device\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store predictions and targets\n",
    "    #sleep_preds = []\n",
    "    #sleep_targets = []\n",
    "    #age_preds = []\n",
    "    #age_targets = []\n",
    "    ahi_diagnosis_preds = []\n",
    "    ahi_diagnosis_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loop = tqdm(test_loader, desc='Evaluating', ncols=100)\n",
    "        \n",
    "        for x_data, y_data, mask, _, _, _, _, _, age_target, ahi_dignosis_target in test_loop:\n",
    "            # Move data to device\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            mask = mask.bool().to(device)\n",
    "            age_target = age_target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, mask, age_out, _, _, ahi_diagnosis = model(x_data, mask)\n",
    "            \n",
    "            # Process sleep staging predictions\n",
    "            output_reshaped = output.reshape(-1, output.size(-1))\n",
    "            targets_reshaped = y_data.reshape(-1).long()\n",
    "            \n",
    "            # Apply masking\n",
    "            if mask is not None:\n",
    "                mask_reshaped = mask.reshape(-1)\n",
    "                valid_targets = targets_reshaped != -1\n",
    "                valid_mask = ~mask_reshaped & valid_targets\n",
    "                \n",
    "                output_reshaped = output_reshaped[valid_mask]\n",
    "                targets_reshaped = targets_reshaped[valid_mask]\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(output_reshaped, 1)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            #sleep_preds.extend(predicted.cpu().numpy().tolist())\n",
    "            #sleep_targets.extend(targets_reshaped.cpu().numpy().tolist())\n",
    "            #age_preds.extend(age_out.cpu().numpy().flatten().tolist())\n",
    "            #age_targets.extend(age_target.cpu().numpy().flatten().tolist())\n",
    "            ahi_diagnosis_preds.extend(torch.sigmoid(ahi_diagnosis).cpu().numpy().flatten().tolist())\n",
    "            ahi_diagnosis_targets.extend(ahi_dignosis_target.cpu().numpy().flatten().tolist())\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        #'sleep_predictions': sleep_preds,\n",
    "        #'sleep_targets': sleep_targets,\n",
    "        #'age_predictions': age_preds,\n",
    "        #'age_targets': age_targets,\n",
    "        'ahi_diagnosis_predictions': ahi_diagnosis_preds,\n",
    "        'ahi_diagnosis_targets': ahi_diagnosis_targets\n",
    "    }\n",
    "    \n",
    "    # Save as numpy arrays\n",
    "    np.save(output_path, results)\n",
    "    print(f'Results saved to {output_path}')\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['lr'] = config['lr'] / 2\n",
    "config['epochs'] = 40\n",
    "config['patience'] = 8\n",
    "config['wandb'] = False\n",
    "config['num_workers'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available GPUs: 1\n",
      "Fine-tuning model with pretrain type: CL_pairwise_epochs_36 for AHI diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oak/stanford/groups/mignot/abk26/conda_envs/SleepBench2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_31527/2202007661.py:59: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 0/39:   0%|                                                                                                                                                                                                                  | 0/18 [00:00<?, ?it/s]/tmp/ipykernel_31527/3634017185.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast() if is_training else torch.no_grad():\n",
      "Epoch 0/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:49<00:00,  2.72s/it, loss=cur:0.848/avg:1.156, sleep=cur:0.000/acc:0.237/f1:0.176, diag=cur:0.000, death=cur:0.000, age=cur:0.261, ahi=cur:0.848/avg:1.156]\n",
      "Validation Epoch 0/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:09<00:00,  1.09s/it, val_loss=cur:0.585/avg:0.958, sleep=cur:0.000/acc:0.212/f1:0.154, diag=cur:0.208, death=cur:0.000, age=cur:0.130, ahi=cur:0.585/avg:0.958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Summary: Training Loss: 1.1565, Accuracy: 0.2374, F1: 0.1759 Validation Loss: 0.9580, Accuracy: 0.2122, F1: 0.1544 Best validation loss: 0.9580 Patience counter: 0/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.30it/s, loss=cur:0.687/avg:0.586, sleep=cur:0.000/acc:0.197/f1:0.153, diag=cur:0.355, death=cur:0.000, age=cur:0.243, ahi=cur:0.687/avg:0.586]\n",
      "Validation Epoch 1/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.67it/s, val_loss=cur:1.198/avg:1.427, sleep=cur:0.000/acc:0.228/f1:0.156, diag=cur:0.200, death=cur:0.000, age=cur:0.085, ahi=cur:1.198/avg:1.427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary: Training Loss: 0.5858, Accuracy: 0.1969, F1: 0.1531 Validation Loss: 1.4273, Accuracy: 0.2284, F1: 0.1559 Best validation loss: 0.9580 Patience counter: 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.28it/s, loss=cur:0.052/avg:0.670, sleep=cur:0.000/acc:0.249/f1:0.170, diag=cur:0.461, death=cur:0.000, age=cur:0.270, ahi=cur:0.052/avg:0.670]\n",
      "Validation Epoch 2/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.65it/s, val_loss=cur:1.630/avg:2.054, sleep=cur:0.000/acc:0.275/f1:0.166, diag=cur:0.212, death=cur:0.000, age=cur:0.261, ahi=cur:1.630/avg:2.054]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary: Training Loss: 0.6699, Accuracy: 0.2494, F1: 0.1697 Validation Loss: 2.0537, Accuracy: 0.2749, F1: 0.1657 Best validation loss: 0.9580 Patience counter: 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.25it/s, loss=cur:0.127/avg:0.460, sleep=cur:0.000/acc:0.253/f1:0.169, diag=cur:0.076, death=cur:0.000, age=cur:0.290, ahi=cur:0.127/avg:0.460]\n",
      "Validation Epoch 3/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.64it/s, val_loss=cur:1.138/avg:1.710, sleep=cur:0.000/acc:0.267/f1:0.168, diag=cur:0.214, death=cur:0.000, age=cur:0.116, ahi=cur:1.138/avg:1.710]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary: Training Loss: 0.4597, Accuracy: 0.2531, F1: 0.1694 Validation Loss: 1.7100, Accuracy: 0.2666, F1: 0.1678 Best validation loss: 0.9580 Patience counter: 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.24it/s, loss=cur:0.228/avg:0.329, sleep=cur:0.000/acc:0.250/f1:0.176, diag=cur:0.000, death=cur:0.000, age=cur:0.168, ahi=cur:0.228/avg:0.329]\n",
      "Validation Epoch 4/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.66it/s, val_loss=cur:1.029/avg:2.368, sleep=cur:0.000/acc:0.226/f1:0.155, diag=cur:0.209, death=cur:0.000, age=cur:0.113, ahi=cur:1.029/avg:2.368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary: Training Loss: 0.3287, Accuracy: 0.2496, F1: 0.1763 Validation Loss: 2.3684, Accuracy: 0.2255, F1: 0.1550 Best validation loss: 0.9580 Patience counter: 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.27it/s, loss=cur:0.718/avg:0.240, sleep=cur:0.000/acc:0.229/f1:0.167, diag=cur:0.690, death=cur:0.000, age=cur:0.270, ahi=cur:0.718/avg:0.240]\n",
      "Validation Epoch 5/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.65it/s, val_loss=cur:0.600/avg:1.795, sleep=cur:0.000/acc:0.262/f1:0.170, diag=cur:0.246, death=cur:0.000, age=cur:0.126, ahi=cur:0.600/avg:1.795]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary: Training Loss: 0.2400, Accuracy: 0.2293, F1: 0.1667 Validation Loss: 1.7948, Accuracy: 0.2622, F1: 0.1697 Best validation loss: 0.9580 Patience counter: 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.29it/s, loss=cur:0.571/avg:0.177, sleep=cur:0.000/acc:0.228/f1:0.163, diag=cur:0.625, death=cur:0.000, age=cur:0.055, ahi=cur:0.571/avg:0.177]\n",
      "Validation Epoch 6/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.66it/s, val_loss=cur:1.608/avg:2.186, sleep=cur:0.000/acc:0.275/f1:0.168, diag=cur:0.242, death=cur:0.000, age=cur:0.128, ahi=cur:1.608/avg:2.186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary: Training Loss: 0.1771, Accuracy: 0.2279, F1: 0.1632 Validation Loss: 2.1863, Accuracy: 0.2755, F1: 0.1681 Best validation loss: 0.9580 Patience counter: 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.29it/s, loss=cur:0.138/avg:0.081, sleep=cur:0.000/acc:0.235/f1:0.165, diag=cur:0.441, death=cur:1.302, age=cur:0.231, ahi=cur:0.138/avg:0.081]\n",
      "Validation Epoch 7/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.68it/s, val_loss=cur:2.139/avg:3.041, sleep=cur:0.000/acc:0.245/f1:0.159, diag=cur:0.245, death=cur:0.000, age=cur:0.090, ahi=cur:2.139/avg:3.041]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary: Training Loss: 0.0813, Accuracy: 0.2349, F1: 0.1646 Validation Loss: 3.0409, Accuracy: 0.2452, F1: 0.1591 Best validation loss: 0.9580 Patience counter: 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/39: 100%|██████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.29it/s, loss=cur:0.001/avg:0.077, sleep=cur:0.000/acc:0.228/f1:0.155, diag=cur:0.540, death=cur:0.000, age=cur:0.117, ahi=cur:0.001/avg:0.077]\n",
      "Validation Epoch 8/39: 100%|█████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.67it/s, val_loss=cur:2.561/avg:2.436, sleep=cur:0.000/acc:0.296/f1:0.171, diag=cur:0.236, death=cur:0.000, age=cur:0.088, ahi=cur:2.561/avg:2.436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered after 9 epochs\n",
      "\n",
      "Training finished!\n",
      "Best validation loss: 0.9580\n",
      "Model saved at /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/results/CL_pairwise_epochs_36/ahi_diagnosis_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/results/CL_pairwise_epochs_36/ahi_diagnosis_results.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace the model initialization section with:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "for pretrain_type in config['pretrain_type']:\n",
    "    print(f'Fine-tuning model with pretrain type: {pretrain_type} for AHI diagnosis')\n",
    "    \n",
    "    # Create datasets and dataloaders - note the increased batch size\n",
    "    train_dataset = SleepEventClassificationDataset(config, split=\"pretrain\", pretrain_type=pretrain_type)\n",
    "    validation_dataset = SleepEventClassificationDataset(config, split=\"validation\", pretrain_type=pretrain_type)\n",
    "    test_dataset = SleepEventClassificationDataset(config, split=\"test\", pretrain_type=pretrain_type)\n",
    "    \n",
    "    # Multiply batch size by number of GPUs since DataParallel splits it automatically\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                            batch_size=config['batch_size'], \n",
    "                            shuffle=True, \n",
    "                            num_workers=config['num_workers'], \n",
    "                            collate_fn=finetune_collate_fn,\n",
    "                            #pin_memory=True, \n",
    "                           drop_last=True)\n",
    "    \n",
    "    validation_loader = DataLoader(validation_dataset, \n",
    "                                 batch_size=(config['batch_size']), \n",
    "                                 shuffle=False, \n",
    "                                 num_workers=config['num_workers'], \n",
    "                                 collate_fn=finetune_collate_fn,\n",
    "                                 #pin_memory=True, \n",
    "                                 drop_last=True)\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                           batch_size=(config['batch_size']), \n",
    "                           shuffle=False, \n",
    "                           num_workers=config['num_workers'], \n",
    "                           collate_fn=finetune_collate_fn,\n",
    "                           #pin_memory=True, \n",
    "                           drop_last=True)\n",
    "\n",
    "    model = SleepEventLSTMClassifier(\n",
    "        embed_dim=config['model_params']['embed_dim'],\n",
    "        num_heads=config['model_params']['num_heads'],\n",
    "        num_layers=config['model_params']['num_layers'],\n",
    "        num_classes=config['model_params']['num_classes'],\n",
    "        pooling_head=config['model_params']['pooling_head'],\n",
    "        dropout=config['model_params']['dropout'],\n",
    "        max_seq_length=config['model_params']['max_seq_length']\n",
    "    )\n",
    "    \n",
    "    # Wrap model with DataParallel before moving to device\n",
    "    if num_gpus > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=[0, 1])  # Explicitly specify GPU devices\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Scale learning rate with number of GPUs\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best_model = train(model, train_loader, validation_loader, optimizer, scaler, config, device, patience=config['patience'])\n",
    "    \n",
    "    #save_path = f'/scratch/users/magnusrk/pretraining_comparision/final_embeddings/{pretrain_type}/ahi_diagnosis_model.pt'\n",
    "    save_path = os.path.join(config['save_path'], f'{pretrain_type}/ahi_diagnosis_model.pt')\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    save_model(best_model, optimizer, scaler, config, save_path)\n",
    "\n",
    "    #output_path = f'/oak/stanford/groups/jamesz/magnusrk/pretraining_comparison_data/ahi_results/{pretrain_type}_ahi_diagnosis_results.npy'\n",
    "    output_path = os.path.join(config['save_path'], f'{pretrain_type}/ahi_diagnosis_results.npy')\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    evaluate_and_save(best_model, test_loader, output_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = f'/oak/stanford/groups/jamesz/magnusrk/pretraining_comparison_data/ahi_results/{pretrain_type}_ahi_diagnosis_results.npy'\n",
    "#evaluate_and_save(model, test_loader, output_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psg_fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
