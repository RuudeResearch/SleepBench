{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd().split('/pretrain_comparison/fine_tune/sleep_stage_and_age')[0] + '/pretrain_comparison')\n",
    "from fine_tune.models.model import SleepEventLSTMClassifier\n",
    "from fine_tune.models.dataset import SleepEventClassificationDataset, finetune_collate_fn\n",
    "from fine_tune.utils import *\n",
    "from comparison.utils import *\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.getcwd().split('/pretrain_comparison/fine_tune/sleep_stage_and_age')[0] + '/pretrain_comparison/fine_tune/config_fine_tune.yaml'\n",
    "config = load_data(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(model, data, optimizer=None, scaler=None, config=None, device=None, mode='train'):\n",
    "    \"\"\"\n",
    "    Run one iteration (batch) of training or validation.\n",
    "    \n",
    "    Args:\n",
    "        model: The PyTorch model\n",
    "        data: Tuple of batch data\n",
    "        optimizer: PyTorch optimizer (only needed for training)\n",
    "        scaler: Gradient scaler for mixed precision training\n",
    "        config: Configuration dictionary\n",
    "        device: PyTorch device\n",
    "        mode: Either 'train' or 'val'\n",
    "    \"\"\"\n",
    "    is_training = mode == 'train'\n",
    "    \n",
    "    # Unpack the batch data\n",
    "    x_data, y_data, mask, _, diagnosis_presence, diagnosis_time, death_presence, death_time, age_target = data\n",
    "\n",
    "    # Compute norms along the feature dimension\n",
    "    norms = x_data.norm(dim=2, keepdim=True)  # Shape: (batch, sequence, 1)\n",
    "\n",
    "    # Normalize the vectors along the feature dimension\n",
    "    x_data_normalized = x_data / (norms + 1e-8)\n",
    "    \n",
    "    # Move data to device\n",
    "    x_data = x_data.to(device)\n",
    "    y_data = y_data.to(device)\n",
    "    mask = mask.bool().to(device)\n",
    "    diagnosis_presence = diagnosis_presence.to(device)\n",
    "    diagnosis_time = diagnosis_time.to(device)\n",
    "    death_presence = death_presence.to(device)\n",
    "    death_time = death_time.to(device)\n",
    "    age_target = age_target.to(device)\n",
    "\n",
    "    if is_training:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Context manager for mixed precision training\n",
    "    with torch.cuda.amp.autocast() if is_training else torch.no_grad():\n",
    "        output, mask, age_out, hazards_diagnosis, hazards_death = model(x_data, mask)\n",
    "        \n",
    "        # Reshape outputs and targets\n",
    "        output_reshaped = output.reshape(-1, config['model_params']['num_classes'])\n",
    "        targets_reshaped = y_data.reshape(-1).long()\n",
    "        \n",
    "        # Handle masking\n",
    "        if mask is not None:\n",
    "            mask_reshaped = mask.reshape(-1)\n",
    "            valid_targets = targets_reshaped != -1\n",
    "            valid_mask = ~mask_reshaped & valid_targets\n",
    "            \n",
    "            output_reshaped = output_reshaped[valid_mask]\n",
    "            targets_reshaped = targets_reshaped[valid_mask]\n",
    "            # if no valid targets set losses to 0 and return\n",
    "            if targets_reshaped.size(0) == 0:\n",
    "                loss = torch.tensor(0.0).to(device)\n",
    "                metrics = {\n",
    "                    'loss': loss.item(),\n",
    "                    'loss_sleep_staging': loss.item(),\n",
    "                    'loss_diagnosis': loss.item(),\n",
    "                    'loss_death': loss.item(),\n",
    "                    'loss_age': loss.item(),\n",
    "                    'correct': 0,\n",
    "                    'total': 0,\n",
    "                    'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "                    'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "                    'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "                }\n",
    "                return metrics\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_sleep_staging = masked_cross_entropy_loss(output, y_data, valid_mask)\n",
    "        loss_diagnosis = cox_ph_loss(hazards_diagnosis, diagnosis_time, diagnosis_presence)\n",
    "        loss_death = cox_ph_loss(hazards_death, death_time, death_presence)\n",
    "        loss_age = F.mse_loss(age_target.float(), age_out.float())\n",
    "        loss = loss_sleep_staging + loss_age * 10\n",
    "\n",
    "    # Handle backpropagation for training\n",
    "    if is_training:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    # Calculate metrics\n",
    "    with torch.no_grad():\n",
    "        _, predicted = torch.max(output_reshaped, 1)\n",
    "        total = targets_reshaped.size(0)\n",
    "        correct = (predicted == targets_reshaped).sum().item()\n",
    "        \n",
    "        # Calculate F1 components\n",
    "        tp = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        fp = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        fn = torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        \n",
    "        for class_idx in range(config['model_params']['num_classes']):\n",
    "            pred_mask = predicted == class_idx\n",
    "            target_mask = targets_reshaped == class_idx\n",
    "            \n",
    "            tp[class_idx] += (pred_mask & target_mask).sum()\n",
    "            fp[class_idx] += (pred_mask & ~target_mask).sum()\n",
    "            fn[class_idx] += (~pred_mask & target_mask).sum()\n",
    "    # Before returning, check for NaN values\n",
    "    metrics = {\n",
    "        'loss': loss.item(),\n",
    "        'loss_sleep_staging': loss_sleep_staging.item(),\n",
    "        'loss_diagnosis': loss_diagnosis.item(),\n",
    "        'loss_death': loss_death.item(),\n",
    "        'loss_age': loss_age.item(),\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    }\n",
    "\n",
    "    # Check for NaN values\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, (float, int)):\n",
    "            if math.isnan(value):\n",
    "                print(f\"NaN detected in {key}\")\n",
    "                print(f\"Debug info:\")\n",
    "                print(f\"loss: {loss}\")\n",
    "                print(f\"loss_sleep_staging: {loss_sleep_staging}\")\n",
    "                print(f\"loss_diagnosis: {loss_diagnosis}\")\n",
    "                print(f\"loss_death: {loss_death}\")\n",
    "                print(f\"loss_age: {loss_age}\")\n",
    "                print(f\"y_data: {y_data}\")\n",
    "                print(f\"output: {output}\")\n",
    "                print(f\"valid_mask: {valid_mask}\")\n",
    "                print(f\"nan in y data: {torch.isnan(y_data).any()}\")\n",
    "                print(f\"nan in output: {torch.isnan(output).any()}\")\n",
    "                print(f\"nan in valid_mask: {torch.isnan(valid_mask).any()}\")\n",
    "                unique_targets_reshaped = torch.unique(targets_reshaped)\n",
    "                print(f\"unique targets: {unique_targets_reshaped}\")\n",
    "                unique_valid_mask = torch.unique(valid_mask)\n",
    "                print(f\"unique valid mask: {unique_valid_mask}\")\n",
    "                raise ValueError(f\"NaN detected in {key}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, optimizer, scaler, config, device, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training metrics\n",
    "        train_metrics = {\n",
    "            'running_loss': 0.0,\n",
    "            'running_sleep_staging_loss': 0.0,\n",
    "            'running_diagnosis_loss': 0.0,\n",
    "            'running_death_loss': 0.0,\n",
    "            'running_age_loss': 0.0,\n",
    "            'correct': 0,\n",
    "            'total': 0,\n",
    "            'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        }\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        train_loop = tqdm(enumerate(train_loader), \n",
    "                            total=len(train_loader), \n",
    "                            desc=f'Epoch {epoch}/{config[\"epochs\"]-1}',\n",
    "                            leave=True,\n",
    "                            ncols=250)\n",
    "        \n",
    "        for i, batch_data in train_loop:\n",
    "            batch_metrics = run_iteration(model, batch_data, optimizer, scaler, config, device, mode='train')\n",
    "            \n",
    "            # Update running metrics\n",
    "            train_metrics['running_loss'] += batch_metrics['loss']\n",
    "            train_metrics['running_sleep_staging_loss'] += batch_metrics['loss_sleep_staging']\n",
    "            train_metrics['running_diagnosis_loss'] += batch_metrics['loss_diagnosis']\n",
    "            train_metrics['running_death_loss'] += batch_metrics['loss_death']\n",
    "            train_metrics['running_age_loss'] += batch_metrics['loss_age']\n",
    "            train_metrics['correct'] += batch_metrics['correct']\n",
    "            train_metrics['total'] += batch_metrics['total']\n",
    "            train_metrics['tp'] += batch_metrics['tp']\n",
    "            train_metrics['fp'] += batch_metrics['fp']\n",
    "            train_metrics['fn'] += batch_metrics['fn']\n",
    "\n",
    "            # Calculate current metrics for progress bar\n",
    "            batch_count = i + 1\n",
    "            avg_loss = train_metrics['running_loss'] / batch_count\n",
    "            accuracy = train_metrics['correct'] / train_metrics['total'] if train_metrics['total'] > 0 else 0\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            precision = train_metrics['tp'] / (train_metrics['tp'] + train_metrics['fp'] + 1e-7)\n",
    "            recall = train_metrics['tp'] / (train_metrics['tp'] + train_metrics['fn'] + 1e-7)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "            macro_f1 = f1.mean().item()\n",
    "\n",
    "            train_loop.set_postfix({\n",
    "                'loss': f'cur:{batch_metrics[\"loss\"]:.3f}/avg:{avg_loss:.3f}',\n",
    "                'sleep': f'cur:{batch_metrics[\"loss_sleep_staging\"]:.3f}/acc:{accuracy:.3f}/f1:{macro_f1:.3f}',\n",
    "                'diag': f'cur:{batch_metrics[\"loss_diagnosis\"]:.3f}',\n",
    "                'death': f'cur:{batch_metrics[\"loss_death\"]:.3f}',\n",
    "                'age': f'cur:{batch_metrics[\"loss_age\"]:.3f}'\n",
    "            })\n",
    "\n",
    "        # Validation loop\n",
    "        val_metrics = {\n",
    "            'running_loss': 0.0,\n",
    "            'running_sleep_staging_loss': 0.0,\n",
    "            'running_diagnosis_loss': 0.0,\n",
    "            'running_death_loss': 0.0,\n",
    "            'running_age_loss': 0.0,\n",
    "            'correct': 0,\n",
    "            'total': 0,\n",
    "            'tp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fp': torch.zeros(config['model_params']['num_classes']).to(device),\n",
    "            'fn': torch.zeros(config['model_params']['num_classes']).to(device)\n",
    "        }\n",
    "\n",
    "        model.eval()\n",
    "        val_loop = tqdm(enumerate(validation_loader), \n",
    "                        total=len(validation_loader), \n",
    "                        desc=f'Validation Epoch {epoch}/{config[\"epochs\"]-1}',\n",
    "                        leave=True,\n",
    "                        ncols=250)\n",
    "        with torch.no_grad():\n",
    "            for i, batch_data in val_loop:\n",
    "                batch_metrics = run_iteration(model, batch_data, None, None, config, device, mode='val')\n",
    "                    \n",
    "                \n",
    "                # Update validation metrics\n",
    "                val_metrics['running_loss'] += batch_metrics['loss']\n",
    "                val_metrics['running_sleep_staging_loss'] += batch_metrics['loss_sleep_staging']\n",
    "                val_metrics['running_diagnosis_loss'] += batch_metrics['loss_diagnosis']\n",
    "                val_metrics['running_death_loss'] += batch_metrics['loss_death']\n",
    "                val_metrics['running_age_loss'] += batch_metrics['loss_age']\n",
    "                val_metrics['correct'] += batch_metrics['correct']\n",
    "                val_metrics['total'] += batch_metrics['total']\n",
    "                val_metrics['tp'] += batch_metrics['tp']\n",
    "                val_metrics['fp'] += batch_metrics['fp']\n",
    "                val_metrics['fn'] += batch_metrics['fn']\n",
    "\n",
    "                # Calculate current metrics\n",
    "                batch_count = i + 1\n",
    "                avg_val_loss = val_metrics['running_loss'] / batch_count\n",
    "                val_accuracy = val_metrics['correct'] / val_metrics['total'] if val_metrics['total'] > 0 else 0\n",
    "                \n",
    "                # Calculate F1 score\n",
    "                precision = val_metrics['tp'] / (val_metrics['tp'] + val_metrics['fp'] + 1e-7)\n",
    "                recall = val_metrics['tp'] / (val_metrics['tp'] + val_metrics['fn'] + 1e-7)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "                val_macro_f1 = f1.mean().item()\n",
    "\n",
    "                val_loop.set_postfix({\n",
    "                    'val_loss': f'cur:{batch_metrics[\"loss\"]:.3f}/avg:{avg_val_loss:.3f}',\n",
    "                    'sleep': f'cur:{batch_metrics[\"loss_sleep_staging\"]:.3f}/acc:{val_accuracy:.3f}/f1:{val_macro_f1:.3f}',\n",
    "                    'diag': f'cur:{batch_metrics[\"loss_diagnosis\"]:.3f}',\n",
    "                    'death': f'cur:{batch_metrics[\"loss_death\"]:.3f}',\n",
    "                    'age': f'cur:{batch_metrics[\"loss_age\"]:.3f}'\n",
    "                })\n",
    "\n",
    "        # Log to wandb if enabled\n",
    "        if config['wandb']:\n",
    "            wandb.log({\n",
    "                'train/loss': avg_loss,\n",
    "                'train/accuracy': accuracy,\n",
    "                'train/f1_score': macro_f1,\n",
    "                'val/loss': avg_val_loss,\n",
    "                'val/accuracy': val_accuracy,\n",
    "                'val/f1_score': val_macro_f1,\n",
    "                'epoch': epoch\n",
    "            })\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping trigger\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "        print(f'\\nEpoch {epoch} Summary: Training Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, F1: {macro_f1:.4f} Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_macro_f1:.4f} Best validation loss: {best_val_loss:.4f} Patience counter: {patience_counter}/{patience}')\n",
    "\n",
    "    print('\\nTraining finished!')\n",
    "    print(f'Best validation loss: {best_val_loss:.4f}') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, test_loader, output_path, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and save predictions and targets.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test set\n",
    "        output_path: Path to save results\n",
    "        device: PyTorch device\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store predictions and targets\n",
    "    sleep_preds = []\n",
    "    sleep_targets = []\n",
    "    age_preds = []\n",
    "    age_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loop = tqdm(test_loader, desc='Evaluating', ncols=100)\n",
    "        \n",
    "        for x_data, y_data, mask, _, _, _, _, _, age_target in test_loop:\n",
    "            # Move data to device\n",
    "            x_data = x_data.to(device)\n",
    "            y_data = y_data.to(device)\n",
    "            mask = mask.bool().to(device)\n",
    "            age_target = age_target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output, mask, age_out, _, _ = model(x_data, mask)\n",
    "            \n",
    "            # Process sleep staging predictions\n",
    "            output_reshaped = output.reshape(-1, output.size(-1))\n",
    "            targets_reshaped = y_data.reshape(-1).long()\n",
    "            \n",
    "            # Apply masking\n",
    "            if mask is not None:\n",
    "                mask_reshaped = mask.reshape(-1)\n",
    "                valid_targets = targets_reshaped != -1\n",
    "                valid_mask = ~mask_reshaped & valid_targets\n",
    "                \n",
    "                output_reshaped = output_reshaped[valid_mask]\n",
    "                targets_reshaped = targets_reshaped[valid_mask]\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(output_reshaped, 1)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            sleep_preds.extend(predicted.cpu().numpy().tolist())\n",
    "            sleep_targets.extend(targets_reshaped.cpu().numpy().tolist())\n",
    "            age_preds.extend(age_out.cpu().numpy().flatten().tolist())\n",
    "            age_targets.extend(age_target.cpu().numpy().flatten().tolist())\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'sleep_predictions': sleep_preds,\n",
    "        'sleep_targets': sleep_targets,\n",
    "        'age_predictions': age_preds,\n",
    "        'age_targets': age_targets\n",
    "    }\n",
    "    \n",
    "    # Save as numpy arrays\n",
    "    np.save(output_path, results)\n",
    "    print(f'Results saved to {output_path}')\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scaler, config, model_path):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'config': config\n",
    "    }, model_path)\n",
    "    print(f'Model saved at {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fine-tuning model with pretrain type: CL_pairwise_epochs_36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embs_path: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings\n",
      "first hdf5_paths_new: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings/CL_pairwise_epochs_36/20250514_043440_epoch_35/SSC_2010_5313980369.hdf5\n",
      "embs_path: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings\n",
      "first hdf5_paths_new: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings/CL_pairwise_epochs_36/20250514_043440_epoch_35/SSC_2010_5313980369.hdf5\n",
      "embs_path: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings\n",
      "first hdf5_paths_new: /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/final_embeddings/CL_pairwise_epochs_36/20250514_043440_epoch_35/SSC_2010_5313980369.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oak/stanford/groups/mignot/abk26/conda_envs/SleepBench2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_18640/2518253682.py:32: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 0/29:   0%|                                                                                                                                                                                                                   | 0/1 [00:00<?, ?it/s]/tmp/ipykernel_18640/3489164764.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast() if is_training else torch.no_grad():\n",
      "Epoch 0/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.45s/it, loss=cur:4.498/avg:4.498, sleep=cur:3.807/acc:0.087/f1:0.054, diag=cur:0.599, death=cur:0.000, age=cur:0.069]\n",
      "Validation Epoch 0/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.03s/it, val_loss=cur:4.209/avg:4.504, sleep=cur:3.565/acc:0.061/f1:0.034, diag=cur:0.000, death=cur:0.000, age=cur:0.064]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Summary: Training Loss: 4.4982, Accuracy: 0.0870, F1: 0.0538 Validation Loss: 4.5036, Accuracy: 0.0609, F1: 0.0341 Best validation loss: 4.5036 Patience counter: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it, loss=cur:4.496/avg:4.496, sleep=cur:3.808/acc:0.090/f1:0.057, diag=cur:0.612, death=cur:0.000, age=cur:0.069]\n",
      "Validation Epoch 1/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.71it/s, val_loss=cur:5.105/avg:5.116, sleep=cur:2.856/acc:0.517/f1:0.136, diag=cur:0.000, death=cur:0.000, age=cur:0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary: Training Loss: 4.4961, Accuracy: 0.0904, F1: 0.0568 Validation Loss: 5.1156, Accuracy: 0.5169, F1: 0.1363 Best validation loss: 4.5036 Patience counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it, loss=cur:5.903/avg:5.903, sleep=cur:3.262/acc:0.535/f1:0.139, diag=cur:0.617, death=cur:0.000, age=cur:0.264]\n",
      "Validation Epoch 2/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.67it/s, val_loss=cur:5.178/avg:5.395, sleep=cur:2.929/acc:0.517/f1:0.136, diag=cur:0.000, death=cur:0.000, age=cur:0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary: Training Loss: 5.9027, Accuracy: 0.5346, F1: 0.1393 Validation Loss: 5.3946, Accuracy: 0.5169, F1: 0.1363 Best validation loss: 4.5036 Patience counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it, loss=cur:5.941/avg:5.941, sleep=cur:3.300/acc:0.535/f1:0.139, diag=cur:0.635, death=cur:0.000, age=cur:0.264]\n",
      "Validation Epoch 3/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.67it/s, val_loss=cur:5.349/avg:5.328, sleep=cur:3.100/acc:0.517/f1:0.136, diag=cur:0.000, death=cur:0.000, age=cur:0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary: Training Loss: 5.9414, Accuracy: 0.5346, F1: 0.1393 Validation Loss: 5.3279, Accuracy: 0.5169, F1: 0.1363 Best validation loss: 4.5036 Patience counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.17it/s, loss=cur:5.851/avg:5.851, sleep=cur:3.209/acc:0.535/f1:0.139, diag=cur:0.631, death=cur:0.000, age=cur:0.264]\n",
      "Validation Epoch 4/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.24it/s, val_loss=cur:5.211/avg:5.204, sleep=cur:2.961/acc:0.517/f1:0.136, diag=cur:0.000, death=cur:0.000, age=cur:0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary: Training Loss: 5.8510, Accuracy: 0.5346, F1: 0.1393 Validation Loss: 5.2043, Accuracy: 0.5169, F1: 0.1363 Best validation loss: 4.5036 Patience counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/29: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s, loss=cur:5.790/avg:5.790, sleep=cur:3.148/acc:0.535/f1:0.139, diag=cur:0.613, death=cur:0.000, age=cur:0.264]\n",
      "Validation Epoch 5/29: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.23it/s, val_loss=cur:5.001/avg:5.109, sleep=cur:2.751/acc:0.517/f1:0.136, diag=cur:0.000, death=cur:0.000, age=cur:0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "\n",
      "Training finished!\n",
      "Best validation loss: 4.5036\n",
      "Model saved at /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/results/CL_pairwise_epochs_36/sleep_stage_and_age_model.pt\n",
      "Saving results to /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/results/CL_pairwise_epochs_36/sleep_stage_and_age_results.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /oak/stanford/groups/mignot/projects/SleepBenchTest/pretrain_comparison/output/results/CL_pairwise_epochs_36/sleep_stage_and_age_results.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "for pretrain_type in config['pretrain_type']:\n",
    "    \n",
    "            \n",
    "        print(f'Fine-tuning model with pretrain type: {pretrain_type}')\n",
    "        output_path = os.path.join(config['save_path'], f'{pretrain_type}/sleep_stage_and_age_results.npy')\n",
    "        #output_path = f'/oak/stanford/groups/jamesz/magnusrk/pretraining_comparison_data/sleep_stage_results/{pretrain_type}_sleep_stage_and_age.npy'\n",
    "        #if output_path folder does not exist, create it\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        \n",
    "        train_dataset = SleepEventClassificationDataset(config, split=\"pretrain\",pretrain_type = pretrain_type)\n",
    "        config['max_files'] = config['val_size']\n",
    "        validation_dataset = SleepEventClassificationDataset(config, split=\"validation\",pretrain_type = pretrain_type)\n",
    "        config['max_files'] = None\n",
    "        test_dataset = SleepEventClassificationDataset(config, split=\"test\",pretrain_type = pretrain_type)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'], collate_fn=finetune_collate_fn)\n",
    "        validation_loader = DataLoader(validation_dataset, batch_size=config['batch_size']//2, shuffle=False, num_workers=config['num_workers'], collate_fn=finetune_collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config['batch_size']//2, shuffle=False, num_workers=config['num_workers'], collate_fn=finetune_collate_fn)\n",
    "\n",
    "        model = SleepEventLSTMClassifier(embed_dim=config['model_params']['embed_dim']\n",
    "                            , num_heads=config['model_params']['num_heads']\n",
    "                            , num_layers=config['model_params']['num_layers']\n",
    "                            , num_classes=config['model_params']['num_classes']\n",
    "                            , pooling_head=config['model_params']['pooling_head']\n",
    "                            , dropout=config['model_params']['dropout']\n",
    "                            , max_seq_length=config['model_params']['max_seq_length'])\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "        model.train()\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        train(model, train_loader, validation_loader, optimizer, scaler, config, device, patience=5)\n",
    "        \n",
    "        save_path = os.path.join(config['save_path'], f'{pretrain_type}/sleep_stage_and_age_model.pt')\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        save_model(model, optimizer, scaler, config, save_path)\n",
    "        \n",
    "        print(f'Saving results to {output_path}')\n",
    "        evaluate_and_save(model, test_loader, output_path, device)\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'Saving results to {output_path}')\n",
    "#evaluate_and_save(model, test_loader, output_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psg_fm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
